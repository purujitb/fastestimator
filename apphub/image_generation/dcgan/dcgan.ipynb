{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN on the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import fastestimator as fe\n",
    "from fastestimator.backend import binary_crossentropy, feed_forward\n",
    "from fastestimator.dataset.data import mnist\n",
    "from fastestimator.op.numpyop import LambdaOp\n",
    "from fastestimator.op.numpyop.univariate import ExpandDims, Normalize\n",
    "from fastestimator.op.tensorop import TensorOp\n",
    "from fastestimator.op.tensorop.model import ModelOp, UpdateOp\n",
    "from fastestimator.trace.io import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 50\n",
    "max_train_steps_per_epoch = None\n",
    "save_dir = tempfile.mkdtemp()\n",
    "model_name = 'model_epoch_50.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building components</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare training and define a `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading data from tf.keras.datasets.mnist and defining a series of operations to perform on the data before the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, _ = mnist.load_data()\n",
    "pipeline = fe.Pipeline(\n",
    "    train_data=train_data,\n",
    "    batch_size=batch_size,\n",
    "    ops=[\n",
    "        ExpandDims(inputs=\"x\", outputs=\"x\"),\n",
    "        Normalize(inputs=\"x\", outputs=\"x\", mean=1.0, std=1.0, max_pixel_value=127.5),\n",
    "        LambdaOp(fn=lambda: np.random.normal(size=[100]).astype('float32'), outputs=\"z\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a `model` and FastEstimator `Network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to define the network architecture for both our <b>Generator</b> and <b>Discriminator</b>. After defining the architecture, users are expected to feed the architecture definition, along with associated model names and optimizers, to fe.build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(100, )))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = fe.build(model_fn=generator, optimizer_fn=lambda: tf.optimizers.Adam(1e-4))\n",
    "disc_model = fe.build(model_fn=discriminator, optimizer_fn=lambda: tf.optimizers.Adam(1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the generator and discriminator losses. These can have multiple inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLoss(TensorOp):\n",
    "    \"\"\"Compute generator loss.\"\"\"\n",
    "    def forward(self, data, state):\n",
    "        return binary_crossentropy(y_pred=data, y_true=tf.ones_like(data), from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLoss(TensorOp):\n",
    "    \"\"\"Compute discriminator loss.\"\"\"\n",
    "    def forward(self, data, state):\n",
    "        true_score, fake_score = data\n",
    "        real_loss = binary_crossentropy(y_pred=true_score, y_true=tf.ones_like(true_score), from_logits=True)\n",
    "        fake_loss = binary_crossentropy(y_pred=fake_score, y_true=tf.zeros_like(fake_score), from_logits=True)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fe.Network` takes series of operators. Here we pass our models wrapped into `ModelOps` along with our loss functions and some update rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = fe.Network(ops=[\n",
    "        ModelOp(model=gen_model, inputs=\"z\", outputs=\"x_fake\"),\n",
    "        ModelOp(model=disc_model, inputs=\"x_fake\", outputs=\"fake_score\"),\n",
    "        GLoss(inputs=\"fake_score\", outputs=\"gloss\"),\n",
    "        UpdateOp(model=gen_model, loss_name=\"gloss\"),\n",
    "        ModelOp(inputs=\"x\", model=disc_model, outputs=\"true_score\"),\n",
    "        DLoss(inputs=(\"true_score\", \"fake_score\"), outputs=\"dloss\"),\n",
    "        UpdateOp(model=disc_model, loss_name=\"dloss\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare `Estimator` and configure the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define an `Estimator` that has four notable arguments: network, pipeline, epochs and traces. Our `Network` and `Pipeline` objects are passed here as an argument along with the number of epochs and a `Trace`, in this case one designed to save our model every 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces=ModelSaver(model=gen_model, save_dir=save_dir, frequency=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = fe.Estimator(pipeline=pipeline,\n",
    "                         network=network,\n",
    "                         epochs=epochs,\n",
    "                         traces=traces,\n",
    "                         max_train_steps_per_epoch=max_train_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Start: step: 1; model_lr: 1e-04; model1_lr: 1e-04; \n",
      "FastEstimator-Train: step: 1; gloss: 0.7122225; dloss: 1.3922014; \n",
      "FastEstimator-Train: step: 100; gloss: 0.906471; dloss: 0.8187004; steps/sec: 10.09; \n",
      "FastEstimator-Train: step: 200; gloss: 0.59155834; dloss: 1.5896755; steps/sec: 9.93; \n",
      "FastEstimator-Train: step: 235; epoch: 1; epoch_time: 28.53 sec; \n",
      "FastEstimator-Train: step: 300; gloss: 0.7163421; dloss: 1.3333399; steps/sec: 8.9; \n",
      "FastEstimator-Train: step: 400; gloss: 0.6816584; dloss: 1.6007018; steps/sec: 9.88; \n",
      "FastEstimator-Train: step: 470; epoch: 2; epoch_time: 23.95 sec; \n",
      "FastEstimator-Train: step: 500; gloss: 0.7051203; dloss: 1.4395489; steps/sec: 9.69; \n",
      "FastEstimator-Train: step: 600; gloss: 0.75529504; dloss: 1.2358603; steps/sec: 9.86; \n",
      "FastEstimator-Train: step: 700; gloss: 0.8082159; dloss: 1.2728964; steps/sec: 9.84; \n",
      "FastEstimator-Train: step: 705; epoch: 3; epoch_time: 24.03 sec; \n",
      "FastEstimator-Train: step: 800; gloss: 0.8434949; dloss: 1.3006642; steps/sec: 9.65; \n",
      "FastEstimator-Train: step: 900; gloss: 0.84470236; dloss: 1.2344811; steps/sec: 9.79; \n",
      "FastEstimator-Train: step: 940; epoch: 4; epoch_time: 24.16 sec; \n",
      "FastEstimator-Train: step: 1000; gloss: 0.9431131; dloss: 1.0444374; steps/sec: 9.66; \n",
      "FastEstimator-Train: step: 1100; gloss: 0.6982814; dloss: 1.5213135; steps/sec: 9.77; \n",
      "Saved model to /tmp/tmpspul4xo8/model_epoch_5.h5\n",
      "FastEstimator-Train: step: 1175; epoch: 5; epoch_time: 24.17 sec; \n",
      "FastEstimator-Train: step: 1200; gloss: 1.2540445; dloss: 0.8278078; steps/sec: 9.63; \n",
      "FastEstimator-Train: step: 1300; gloss: 0.70465124; dloss: 1.7595482; steps/sec: 9.76; \n",
      "FastEstimator-Train: step: 1400; gloss: 0.83103234; dloss: 1.168882; steps/sec: 9.77; \n",
      "FastEstimator-Train: step: 1410; epoch: 6; epoch_time: 24.22 sec; \n",
      "FastEstimator-Train: step: 1500; gloss: 0.86833733; dloss: 1.2078841; steps/sec: 9.57; \n",
      "FastEstimator-Train: step: 1600; gloss: 0.82795817; dloss: 1.2242851; steps/sec: 9.75; \n",
      "FastEstimator-Train: step: 1645; epoch: 7; epoch_time: 24.3 sec; \n",
      "FastEstimator-Train: step: 1700; gloss: 0.9743507; dloss: 1.0731742; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 1800; gloss: 0.89325964; dloss: 1.1766281; steps/sec: 9.76; \n",
      "FastEstimator-Train: step: 1880; epoch: 8; epoch_time: 24.25 sec; \n",
      "FastEstimator-Train: step: 1900; gloss: 1.0287898; dloss: 0.9916363; steps/sec: 9.6; \n",
      "FastEstimator-Train: step: 2000; gloss: 0.8240694; dloss: 1.313368; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 2100; gloss: 0.9738071; dloss: 1.1259043; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 2115; epoch: 9; epoch_time: 24.3 sec; \n",
      "FastEstimator-Train: step: 2200; gloss: 1.0899432; dloss: 1.0272337; steps/sec: 9.57; \n",
      "FastEstimator-Train: step: 2300; gloss: 0.868231; dloss: 1.2400149; steps/sec: 9.72; \n",
      "Saved model to /tmp/tmpspul4xo8/model_epoch_10.h5\n",
      "FastEstimator-Train: step: 2350; epoch: 10; epoch_time: 24.35 sec; \n",
      "FastEstimator-Train: step: 2400; gloss: 0.9001913; dloss: 1.1931081; steps/sec: 9.58; \n",
      "FastEstimator-Train: step: 2500; gloss: 1.0865673; dloss: 0.8990781; steps/sec: 9.71; \n",
      "FastEstimator-Train: step: 2585; epoch: 11; epoch_time: 24.34 sec; \n",
      "FastEstimator-Train: step: 2600; gloss: 0.7485407; dloss: 1.672249; steps/sec: 9.58; \n",
      "FastEstimator-Train: step: 2700; gloss: 1.045316; dloss: 1.0383615; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 2800; gloss: 0.7666995; dloss: 1.4343789; steps/sec: 9.72; \n",
      "FastEstimator-Train: step: 2820; epoch: 12; epoch_time: 24.3 sec; \n",
      "FastEstimator-Train: step: 2900; gloss: 1.1756387; dloss: 0.96622103; steps/sec: 9.6; \n",
      "FastEstimator-Train: step: 3000; gloss: 0.9090629; dloss: 1.1984154; steps/sec: 9.72; \n",
      "FastEstimator-Train: step: 3055; epoch: 13; epoch_time: 24.29 sec; \n",
      "FastEstimator-Train: step: 3100; gloss: 0.9301505; dloss: 1.113826; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 3200; gloss: 0.99965835; dloss: 1.0707076; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 3290; epoch: 14; epoch_time: 24.31 sec; \n",
      "FastEstimator-Train: step: 3300; gloss: 0.80838567; dloss: 1.6384692; steps/sec: 9.55; \n",
      "FastEstimator-Train: step: 3400; gloss: 0.8714433; dloss: 1.326818; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 3500; gloss: 0.9549879; dloss: 1.2086997; steps/sec: 9.73; \n",
      "Saved model to /tmp/tmpspul4xo8/model_epoch_15.h5\n",
      "FastEstimator-Train: step: 3525; epoch: 15; epoch_time: 24.34 sec; \n",
      "FastEstimator-Train: step: 3600; gloss: 1.0164418; dloss: 1.0690243; steps/sec: 9.57; \n",
      "FastEstimator-Train: step: 3700; gloss: 1.0357686; dloss: 1.0537144; steps/sec: 9.72; \n",
      "FastEstimator-Train: step: 3760; epoch: 16; epoch_time: 24.32 sec; \n",
      "FastEstimator-Train: step: 3800; gloss: 0.7402923; dloss: 1.4840925; steps/sec: 9.6; \n",
      "FastEstimator-Train: step: 3900; gloss: 0.91192436; dloss: 1.3617609; steps/sec: 9.72; \n",
      "FastEstimator-Train: step: 3995; epoch: 17; epoch_time: 24.3 sec; \n",
      "FastEstimator-Train: step: 4000; gloss: 1.2626994; dloss: 0.9568275; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 4100; gloss: 0.97824305; dloss: 1.300906; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 4200; gloss: 0.93075603; dloss: 1.387594; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 4230; epoch: 18; epoch_time: 24.31 sec; \n",
      "FastEstimator-Train: step: 4300; gloss: 1.0180345; dloss: 1.0898602; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 4400; gloss: 1.051662; dloss: 1.3392837; steps/sec: 9.71; \n",
      "FastEstimator-Train: step: 4465; epoch: 19; epoch_time: 24.33 sec; \n",
      "FastEstimator-Train: step: 4500; gloss: 1.0151768; dloss: 1.1482071; steps/sec: 9.56; \n",
      "FastEstimator-Train: step: 4600; gloss: 1.107022; dloss: 0.96815336; steps/sec: 9.71; \n",
      "FastEstimator-Train: step: 4700; gloss: 1.0924942; dloss: 1.1389236; steps/sec: 9.72; \n",
      "Saved model to /tmp/tmpspul4xo8/model_epoch_20.h5\n",
      "FastEstimator-Train: step: 4700; epoch: 20; epoch_time: 24.39 sec; \n",
      "FastEstimator-Train: step: 4800; gloss: 1.1345683; dloss: 1.2068424; steps/sec: 9.54; \n",
      "FastEstimator-Train: step: 4900; gloss: 1.142304; dloss: 0.9673606; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 4935; epoch: 21; epoch_time: 24.3 sec; \n",
      "FastEstimator-Train: step: 5000; gloss: 0.9886; dloss: 1.0960109; steps/sec: 9.57; \n",
      "FastEstimator-Train: step: 5100; gloss: 0.8936993; dloss: 1.2922779; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 5170; epoch: 22; epoch_time: 24.3 sec; \n",
      "FastEstimator-Train: step: 5200; gloss: 1.1095095; dloss: 1.1243165; steps/sec: 9.57; \n",
      "FastEstimator-Train: step: 5300; gloss: 1.2485275; dloss: 0.89292765; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 5400; gloss: 1.0476826; dloss: 1.2994311; steps/sec: 9.75; \n",
      "FastEstimator-Train: step: 5405; epoch: 23; epoch_time: 24.29 sec; \n",
      "FastEstimator-Train: step: 5500; gloss: 1.3308836; dloss: 0.871735; steps/sec: 9.63; \n",
      "FastEstimator-Train: step: 5600; gloss: 1.115385; dloss: 1.2837725; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 5640; epoch: 24; epoch_time: 24.23 sec; \n",
      "FastEstimator-Train: step: 5700; gloss: 1.1920481; dloss: 1.0993654; steps/sec: 9.62; \n",
      "FastEstimator-Train: step: 5800; gloss: 1.3005233; dloss: 0.914361; steps/sec: 9.74; \n",
      "Saved model to /tmp/tmpspul4xo8/model_epoch_25.h5\n",
      "FastEstimator-Train: step: 5875; epoch: 25; epoch_time: 24.27 sec; \n",
      "FastEstimator-Train: step: 5900; gloss: 1.3146336; dloss: 0.8816396; steps/sec: 9.6; \n",
      "FastEstimator-Train: step: 6000; gloss: 0.9764897; dloss: 1.289681; steps/sec: 9.75; \n",
      "FastEstimator-Train: step: 6100; gloss: 1.1467731; dloss: 1.1918977; steps/sec: 9.75; \n",
      "FastEstimator-Train: step: 6110; epoch: 26; epoch_time: 24.26 sec; \n",
      "FastEstimator-Train: step: 6200; gloss: 1.6301311; dloss: 0.9541445; steps/sec: 9.6; \n",
      "FastEstimator-Train: step: 6300; gloss: 1.2840165; dloss: 0.9587291; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 6345; epoch: 27; epoch_time: 24.3 sec; \n",
      "FastEstimator-Train: step: 6400; gloss: 1.1097628; dloss: 1.0090048; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 6500; gloss: 1.2495477; dloss: 0.89897555; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 6580; epoch: 28; epoch_time: 24.32 sec; \n",
      "FastEstimator-Train: step: 6600; gloss: 1.1773547; dloss: 1.1330662; steps/sec: 9.58; \n",
      "FastEstimator-Train: step: 6700; gloss: 1.246088; dloss: 0.8964198; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 6800; gloss: 1.2250234; dloss: 1.0358574; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 6815; epoch: 29; epoch_time: 24.3 sec; \n",
      "FastEstimator-Train: step: 6900; gloss: 1.1256618; dloss: 1.196687; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 7000; gloss: 1.1131527; dloss: 1.0596428; steps/sec: 9.73; \n",
      "Saved model to /tmp/tmpspul4xo8/model_epoch_30.h5\n",
      "FastEstimator-Train: step: 7050; epoch: 30; epoch_time: 24.31 sec; \n",
      "FastEstimator-Train: step: 7100; gloss: 1.1662202; dloss: 1.0555116; steps/sec: 9.57; \n",
      "FastEstimator-Train: step: 7200; gloss: 1.0653521; dloss: 1.1444951; steps/sec: 9.71; \n",
      "FastEstimator-Train: step: 7285; epoch: 31; epoch_time: 24.36 sec; \n",
      "FastEstimator-Train: step: 7300; gloss: 1.1732882; dloss: 1.1456137; steps/sec: 9.56; \n",
      "FastEstimator-Train: step: 7400; gloss: 1.0872216; dloss: 1.128233; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 7500; gloss: 1.2431256; dloss: 1.1538315; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 7520; epoch: 32; epoch_time: 24.31 sec; \n",
      "FastEstimator-Train: step: 7600; gloss: 1.0806718; dloss: 1.2206206; steps/sec: 9.57; \n",
      "FastEstimator-Train: step: 7700; gloss: 1.1804712; dloss: 1.1420157; steps/sec: 9.71; \n",
      "FastEstimator-Train: step: 7755; epoch: 33; epoch_time: 24.36 sec; \n",
      "FastEstimator-Train: step: 7800; gloss: 1.1762993; dloss: 1.0413929; steps/sec: 9.54; \n",
      "FastEstimator-Train: step: 7900; gloss: 1.2267275; dloss: 0.98290396; steps/sec: 9.71; \n",
      "FastEstimator-Train: step: 7990; epoch: 34; epoch_time: 24.37 sec; \n",
      "FastEstimator-Train: step: 8000; gloss: 1.1847881; dloss: 1.0905983; steps/sec: 9.55; \n",
      "FastEstimator-Train: step: 8100; gloss: 1.1490288; dloss: 1.1739209; steps/sec: 9.72; \n",
      "FastEstimator-Train: step: 8200; gloss: 1.0283768; dloss: 1.059457; steps/sec: 9.73; \n",
      "Saved model to /tmp/tmpspul4xo8/model_epoch_35.h5\n",
      "FastEstimator-Train: step: 8225; epoch: 35; epoch_time: 24.33 sec; \n",
      "FastEstimator-Train: step: 8300; gloss: 1.2351133; dloss: 1.1085691; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 8400; gloss: 1.1488228; dloss: 1.1410246; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 8460; epoch: 36; epoch_time: 24.31 sec; \n",
      "FastEstimator-Train: step: 8500; gloss: 1.152446; dloss: 1.1371456; steps/sec: 9.55; \n",
      "FastEstimator-Train: step: 8600; gloss: 1.2175394; dloss: 1.1543391; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 8695; epoch: 37; epoch_time: 24.31 sec; \n",
      "FastEstimator-Train: step: 8700; gloss: 1.1803217; dloss: 1.1517241; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 8800; gloss: 0.9561673; dloss: 1.2418871; steps/sec: 9.77; \n",
      "FastEstimator-Train: step: 8900; gloss: 1.0239995; dloss: 1.243228; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 8930; epoch: 38; epoch_time: 24.26 sec; \n",
      "FastEstimator-Train: step: 9000; gloss: 0.98074543; dloss: 1.2558163; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 9100; gloss: 1.0084043; dloss: 1.2773612; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 9165; epoch: 39; epoch_time: 24.3 sec; \n",
      "FastEstimator-Train: step: 9200; gloss: 1.0313301; dloss: 1.2312038; steps/sec: 9.58; \n",
      "FastEstimator-Train: step: 9300; gloss: 1.0100834; dloss: 1.2482088; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 9400; gloss: 0.9327201; dloss: 1.3188391; steps/sec: 9.73; \n",
      "Saved model to /tmp/tmpspul4xo8/model_epoch_40.h5\n",
      "FastEstimator-Train: step: 9400; epoch: 40; epoch_time: 24.34 sec; \n",
      "FastEstimator-Train: step: 9500; gloss: 1.1315899; dloss: 1.1447232; steps/sec: 9.55; \n",
      "FastEstimator-Train: step: 9600; gloss: 1.1352619; dloss: 1.0802212; steps/sec: 9.72; \n",
      "FastEstimator-Train: step: 9635; epoch: 41; epoch_time: 24.3 sec; \n",
      "FastEstimator-Train: step: 9700; gloss: 1.01453; dloss: 1.0975459; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 9800; gloss: 0.90930146; dloss: 1.2942967; steps/sec: 9.76; \n",
      "FastEstimator-Train: step: 9870; epoch: 42; epoch_time: 24.27 sec; \n",
      "FastEstimator-Train: step: 9900; gloss: 1.0540565; dloss: 1.170531; steps/sec: 9.58; \n",
      "FastEstimator-Train: step: 10000; gloss: 1.061863; dloss: 1.2722391; steps/sec: 9.76; \n",
      "FastEstimator-Train: step: 10100; gloss: 0.9647354; dloss: 1.1689386; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 10105; epoch: 43; epoch_time: 24.29 sec; \n",
      "FastEstimator-Train: step: 10200; gloss: 1.2080085; dloss: 1.075758; steps/sec: 9.57; \n",
      "FastEstimator-Train: step: 10300; gloss: 1.0741084; dloss: 1.1352613; steps/sec: 9.72; \n",
      "FastEstimator-Train: step: 10340; epoch: 44; epoch_time: 24.34 sec; \n",
      "FastEstimator-Train: step: 10400; gloss: 1.1394867; dloss: 0.9788251; steps/sec: 9.58; \n",
      "FastEstimator-Train: step: 10500; gloss: 1.1983887; dloss: 1.0792823; steps/sec: 9.73; \n",
      "Saved model to /tmp/tmpspul4xo8/model_epoch_45.h5\n",
      "FastEstimator-Train: step: 10575; epoch: 45; epoch_time: 24.31 sec; \n",
      "FastEstimator-Train: step: 10600; gloss: 0.96989757; dloss: 1.2448618; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 10700; gloss: 0.9579427; dloss: 1.2773428; steps/sec: 9.7; \n",
      "FastEstimator-Train: step: 10800; gloss: 0.97453225; dloss: 1.2194138; steps/sec: 9.72; \n",
      "FastEstimator-Train: step: 10810; epoch: 46; epoch_time: 24.36 sec; \n",
      "FastEstimator-Train: step: 10900; gloss: 1.0218571; dloss: 1.1765122; steps/sec: 9.57; \n",
      "FastEstimator-Train: step: 11000; gloss: 1.1221988; dloss: 1.1675267; steps/sec: 9.71; \n",
      "FastEstimator-Train: step: 11045; epoch: 47; epoch_time: 24.34 sec; \n",
      "FastEstimator-Train: step: 11100; gloss: 0.900293; dloss: 1.1741953; steps/sec: 9.57; \n",
      "FastEstimator-Train: step: 11200; gloss: 1.1080045; dloss: 1.1090837; steps/sec: 9.73; \n",
      "FastEstimator-Train: step: 11280; epoch: 48; epoch_time: 24.31 sec; \n",
      "FastEstimator-Train: step: 11300; gloss: 1.1028197; dloss: 1.1044464; steps/sec: 9.59; \n",
      "FastEstimator-Train: step: 11400; gloss: 1.0530615; dloss: 1.2150866; steps/sec: 9.74; \n",
      "FastEstimator-Train: step: 11500; gloss: 0.8997061; dloss: 1.3101699; steps/sec: 9.75; \n",
      "FastEstimator-Train: step: 11515; epoch: 49; epoch_time: 24.29 sec; \n",
      "FastEstimator-Train: step: 11600; gloss: 1.0087067; dloss: 1.3297874; steps/sec: 9.58; \n",
      "FastEstimator-Train: step: 11700; gloss: 1.0053492; dloss: 1.2499433; steps/sec: 9.74; \n",
      "Saved model to /tmp/tmpspul4xo8/model_epoch_50.h5\n",
      "FastEstimator-Train: step: 11750; epoch: 50; epoch_time: 24.3 sec; \n",
      "FastEstimator-Finish: step: 11750; total_time: 1219.47 sec; model_lr: 1e-04; model1_lr: 1e-04; \n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Inferencing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For inferencing, first we have to load the trained model weights. We will load the trained generator weights using <i>fe.build</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from /tmp/tmpspul4xo8/model_epoch_50.h5\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(save_dir, model_name)\n",
    "trained_model = fe.build(model_fn=generator, weights_path=model_path, optimizer_fn=lambda: tf.optimizers.Adam(1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will the generate some images from random noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images = feed_forward(trained_model, np.random.normal(size=(16, 100)), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4, 4)\n",
    "axes = np.ravel(axes)\n",
    "for i in range(images.shape[0]):\n",
    "    axes[i].axis('off')\n",
    "    axes[i].imshow(np.squeeze(images[i, ...] * 127.5 + 127.5), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}