{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Tutorial 5: Scheduler\n",
    "In this tutorial, we will talk about:\n",
    "* [Scheduler](#ta05scheduler)\n",
    "    * [Concept](#ta05concept)\n",
    "    * [EpochScheduler](#ta05epoch)\n",
    "    * [RepeatScheduler](#ta05repeat)\n",
    "* [Things You Can Schedule](#ta05things)\n",
    "    * [Datasets](#ta05dataset)\n",
    "    * [Batch Size](#ta05batch)\n",
    "    * [NumpyOps](#ta05numpy)\n",
    "    * [Optimizers](#ta05optimizer)\n",
    "    * [TensorOps](#ta05tensor)\n",
    "    * [Traces](#ta05trace)\n",
    "* [Related Apphub Examples](#ta05apphub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05scheduler'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05concept'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept\n",
    "Deep learning training is getting more complicated every year. One major aspect of this complexity is time-dependent training. For example:\n",
    "\n",
    "* Using different datasets for different training epochs.\n",
    "* Applying different preprocessing for different epochs.\n",
    "* Training different networks on different epochs. \n",
    "* ...\n",
    "\n",
    "The list goes on and on. In order to provide an easy way for users to accomplish time-dependent training, we provide the `Scheduler` class which can help you schedule any part of the training. \n",
    "\n",
    "Please note that the basic time unit that `Scheduler` can handle is `epochs`. If users want arbitrary scheduling cycles, the simplest way is to customize the length of one epoch in `Estimator` using max_train_steps_per_epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05epoch'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EpochScheduler\n",
    "The most straightforward way to schedule things is through an epoch-value mapping. For example, If users want to schedule the batch size in the following way:\n",
    "\n",
    "* epoch 1 - batchsize 16\n",
    "* epoch 2 - batchsize 32\n",
    "* epoch 3 - batchsize 32\n",
    "* epoch 4 - batchsize 64\n",
    "* epoch 5 - batchsize 64\n",
    "\n",
    "You can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.schedule import EpochScheduler\n",
    "batch_size = EpochScheduler(epoch_dict={1:16, 2:32, 4:64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 1, batch size is 16\n",
      "At epoch 2, batch size is 32\n",
      "At epoch 3, batch size is 32\n",
      "At epoch 4, batch size is 64\n",
      "At epoch 5, batch size is 64\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    print(\"At epoch {}, batch size is {}\".format(epoch, batch_size.get_current_value(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05repeat'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RepeatScheduler\n",
    "If your schedule follows a repeating pattern, then you don't want to specify that for all epochs. `RepeatScheduler` is here to help you. Let's say we want the batch size on odd epochs to be 32, and on even epochs to be 64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 1, batch size is 32\n",
      "At epoch 2, batch size is 64\n",
      "At epoch 3, batch size is 32\n",
      "At epoch 4, batch size is 64\n",
      "At epoch 5, batch size is 32\n"
     ]
    }
   ],
   "source": [
    "from fastestimator.schedule import RepeatScheduler\n",
    "batch_size = RepeatScheduler(repeat_list=[32, 64])\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    print(\"At epoch {}, batch size is {}\".format(epoch, batch_size.get_current_value(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05things'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things You Can Schedule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05dataset'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "Scheduling training or evaluation datasets is very common in deep learning. For example, in curriculum learning people will train on an easy dataset first and then gradually move on to harder datasets. For illustration purposes, let's use two different instances of the same MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.dataset.data import mnist, cifar10\n",
    "from fastestimator.schedule import EpochScheduler\n",
    "\n",
    "train_data1, eval_data = mnist.load_data()\n",
    "train_data2, _ = mnist.load_data()\n",
    "train_data = EpochScheduler(epoch_dict={1:train_data1, 3: train_data2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05batch'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Size\n",
    "We can also schedule the batch size on different epochs, which may help resolve GPU resource constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = RepeatScheduler(repeat_list=[32,64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05numpy'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumpyOps\n",
    "Preprocessing operators can also be scheduled. For illustration purpose, we will apply a `Rotation` for the first two epochs and then not apply it for the third epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.numpyop.univariate import ExpandDims, Minmax\n",
    "from fastestimator.op.numpyop.multivariate import Rotate\n",
    "import fastestimator as fe\n",
    "\n",
    "rotate_op = EpochScheduler(epoch_dict={1:Rotate(image_in=\"x\", image_out=\"x\",limit=30), 3:None})\n",
    "\n",
    "pipeline = fe.Pipeline(train_data=train_data, \n",
    "                       eval_data=eval_data,\n",
    "                       batch_size=batch_size, \n",
    "                       ops=[ExpandDims(inputs=\"x\", outputs=\"x\"), rotate_op, Minmax(inputs=\"x\", outputs=\"x\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05optimizer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    "For fast convergence, some people like to use different optimizers at different training phases. In our example, we will use `adam` for the first epoch and `sgd` for the second epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.architecture.tensorflow import LeNet\n",
    "\n",
    "model_1 = fe.build(model_fn=LeNet, optimizer_fn=EpochScheduler(epoch_dict={1:\"adam\", 2: \"sgd\"}), model_name=\"m1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05tensor'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorOps\n",
    "We can schedule `TensorOps` just like `NumpyOps`. Let's define another model `model_2` such that:\n",
    "* epoch 1-2: train `model_1`\n",
    "* epoch 3: train `model_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.tensorop.model import ModelOp, UpdateOp\n",
    "from fastestimator.op.tensorop.loss import CrossEntropy\n",
    "\n",
    "model_2 = fe.build(model_fn=LeNet, optimizer_fn=\"adam\", model_name=\"m2\")\n",
    "\n",
    "model_map = {1: ModelOp(model=model_1, inputs=\"x\", outputs=\"y_pred\"), \n",
    "             3: ModelOp(model=model_2, inputs=\"x\", outputs=\"y_pred\")}\n",
    "\n",
    "update_map = {1: UpdateOp(model=model_1, loss_name=\"ce\"), 3: UpdateOp(model=model_2, loss_name=\"ce\")}\n",
    "\n",
    "network = fe.Network(ops=[EpochScheduler(model_map),\n",
    "                          CrossEntropy(inputs=(\"y_pred\", \"y\"), outputs=\"ce\"),\n",
    "                          EpochScheduler(update_map)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05trace'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traces\n",
    "`Traces` can also be scheduled. For example, we will save `model_1` at the end of second epoch and save `model_3` at the end of third epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.trace.io import ModelSaver\n",
    "import tempfile\n",
    "\n",
    "save_folder = tempfile.mkdtemp()\n",
    "\n",
    "#Disable model saving by setting None on 3rd epoch:\n",
    "modelsaver1 = EpochScheduler({2:ModelSaver(model=model_1,save_dir=save_folder), 3:None})\n",
    "\n",
    "modelsaver2 = EpochScheduler({3:ModelSaver(model=model_2,save_dir=save_folder)})\n",
    "\n",
    "traces=[modelsaver1, modelsaver2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let the training begin\n",
    "Nothing special in here, create the estimator then start the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Start: step: 1; num_device: 1; logging_interval: 300; \n",
      "FastEstimator-Train: step: 1; ce: 0.016785031; \n",
      "FastEstimator-Train: step: 300; ce: 0.16430134; steps/sec: 697.26; \n",
      "FastEstimator-Train: step: 600; ce: 0.023913195; steps/sec: 728.45; \n",
      "FastEstimator-Train: step: 900; ce: 0.042380013; steps/sec: 732.24; \n",
      "FastEstimator-Train: step: 1200; ce: 0.0014684915; steps/sec: 723.88; \n",
      "FastEstimator-Train: step: 1500; ce: 0.020901386; steps/sec: 728.1; \n",
      "FastEstimator-Train: step: 1800; ce: 0.0114256; steps/sec: 724.26; \n",
      "FastEstimator-Train: step: 1875; epoch: 1; epoch_time: 2.66 sec; \n",
      "FastEstimator-Eval: step: 1875; epoch: 1; ce: 0.054206606; \n",
      "FastEstimator-Train: step: 2100; ce: 0.023387551; steps/sec: 546.57; \n",
      "FastEstimator-Train: step: 2400; ce: 0.0030879583; steps/sec: 627.71; \n",
      "FastEstimator-Train: step: 2700; ce: 0.10354612; steps/sec: 631.19; \n",
      "FastEstimator-ModelSaver: Saved model to /tmp/tmph72ava81/m1_epoch_2.h5\n",
      "FastEstimator-Train: step: 2813; epoch: 2; epoch_time: 1.58 sec; \n",
      "FastEstimator-Eval: step: 2813; epoch: 2; ce: 0.040080495; \n",
      "FastEstimator-Train: step: 3000; ce: 0.0011174735; steps/sec: 627.96; \n",
      "FastEstimator-Train: step: 3300; ce: 0.019162945; steps/sec: 792.26; \n",
      "FastEstimator-Train: step: 3600; ce: 0.21189407; steps/sec: 796.04; \n",
      "FastEstimator-Train: step: 3900; ce: 0.0007937134; steps/sec: 811.5; \n",
      "FastEstimator-Train: step: 4200; ce: 0.002208311; steps/sec: 818.86; \n",
      "FastEstimator-Train: step: 4500; ce: 0.005765636; steps/sec: 815.32; \n",
      "FastEstimator-ModelSaver: Saved model to /tmp/tmph72ava81/m2_epoch_3.h5\n",
      "FastEstimator-Train: step: 4688; epoch: 3; epoch_time: 2.4 sec; \n",
      "FastEstimator-Eval: step: 4688; epoch: 3; ce: 0.033545353; \n",
      "FastEstimator-Finish: step: 4688; total_time: 10.79 sec; m2_lr: 0.001; m1_lr: 0.01; \n"
     ]
    }
   ],
   "source": [
    "estimator = fe.Estimator(pipeline=pipeline, network=network, traces=traces, epochs=3, log_steps=300)\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta05apphub'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apphub Examples\n",
    "You can find some practical examples of the concepts described here in the following FastEstimator Apphubs:\n",
    "\n",
    "* [PGGAN](../../apphub/image_generation/pggan/pggan.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
